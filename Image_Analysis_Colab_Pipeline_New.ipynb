{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Image_Analysis_Colab_Pipeline_New.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hincz-lab/DeepLearning-SCDBiochip/blob/master/Image_Analysis_Colab_Pipeline_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLJ5kBCrRCj6"
      },
      "source": [
        "## Clone Repository, Change Working Directory, And Download Libraries/Packages.\r\n",
        "Run the following cell one time. The SCD-monitoring_ML-tool Directory Will Populate In The User Interface To The Left (Click The Folder Icon And Go To \"Content\").\r\n",
        "\r\n",
        "Also, the necessary libraries and functions will be loaded from the downloaded set, as well as extracted from a google drive.\r\n",
        "\r\n",
        "Next, the networks being used will be downloaded. Don't worry if it takes several minutes to load because there are several network weights to download. All of the pretrained weights will be saved in automatic folders called \"./Phase2_Pretrained-models/\" for phase 2 networks, or \"./Phase1_Pretrained-models/\" for phase 1 networks.\r\n",
        "\r\n",
        "We expect seven networks in the phase 1 ensenble, and five networks in the phase 2 ensemble.\r\n",
        "\r\n",
        "Next, you will create a directory which will hold all of the images that will be analyzed by the network.\r\n",
        "\r\n",
        "It is important to note here that you will need to manually upload images to the correct directory, which is located at: content -> SCD-monitoring_ML-tool -> data -> Images_To_Be_Analyzed.\r\n",
        "\r\n",
        "To upload images, right-click the Images_To_Be_Analyzed folder and select \"Upload\". Then, navigate to and select whole channel images which you would like to be analyzed.\r\n",
        "\r\n",
        "Make sure to wait until all images are properly uploaded before executing further code (You can see the status as an orange ring in the bottom-left corner of the screen).\r\n",
        "\r\n",
        "IMPORTANT: It is recommended to do your analysis in batches, instead of uploading all whole channel images at once. After completing one batch, simply re-run the following cell, which will clear out the Images_To_Be_Analyzed directory, and then you can upload more channels for analysis.\r\n",
        "\r\n",
        "Lastly, the code will import other useful functions for the analysis of channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcwMaAzgTr8H",
        "cellView": "form"
      },
      "source": [
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "print(\"Cloning Repository...\")\n",
        "!git clone https://github.com/hincz-lab/SCD-monitoring_ML-tool &> /dev/null\n",
        "print(\"Complete!\")\n",
        "print('==================================================================')\n",
        "%cd SCD-monitoring_ML-tool\n",
        "print(\"Is the New Working Directory.\")\n",
        "print('==================================================================')\n",
        "print(\"Installing Necessary Libraries And Packages To Environment...\")\n",
        "!pip install -r requirement.txt &> /dev/null\n",
        "print(\"Complete!\")\n",
        "\n",
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "print(\"Importing...\")\n",
        "import tensorflow as tf\n",
        "import keras as K\n",
        "# load processing func\n",
        "import source.toolkit_loc as tk\n",
        "import source.dojo_tools as dj\n",
        "\n",
        "from source.toolkit_loc import list_channels\n",
        "from source.toolkit_loc import list_channels_df\n",
        "\n",
        "# load main class object for monitoring blood cells\n",
        "from source.Image_Analysis_New  import CountAdheredBloodCells\n",
        "\n",
        "# loading tools for extracting gdrive data\n",
        "import source.load_data_tools_loc as loading_tools\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import gdown\n",
        "from natsort import natsorted\n",
        "print(\"Complete!\")\n",
        "\n",
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "\n",
        "print(\"Downloading Phase 2 Weights...\")\n",
        "os.makedirs(f'./Phase2_Pretrained-models/Resnet50/', exist_ok = True)\n",
        "os.chdir(f'./Phase2_Pretrained-models/Resnet50/') \n",
        "\n",
        "loading_tools.resnet50_gdrive_()\n",
        "print(\"Complete!\")\n",
        "print('==================================================================')\n",
        "os.chdir(f'../')\n",
        "os.chdir(f'../')\n",
        "\n",
        "print(\"Downloading Phase 1 Weights...\")\n",
        "os.makedirs(f'./Phase1_Pretrained-models/ce-jaccard_encoder-decoder-net/', exist_ok = True)\n",
        "os.chdir(f'./Phase1_Pretrained-models/ce-jaccard_encoder-decoder-net/') \n",
        "\n",
        "loading_tools.ce_jaccard_gdrive_()\n",
        "print(\"Complete!\")\n",
        "os.chdir(f'../')\n",
        "os.chdir(f'../')\n",
        "\n",
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "' Download channel images from gdrive ... '\n",
        "print(\"Creating Image Analysis Directory...\")\n",
        "import shutil\n",
        "channel_path= './data/Images_To_Be_Analyzed/'\n",
        "if os.path.isdir(channel_path):\n",
        "  shutil.rmtree(channel_path)\n",
        "os.makedirs(channel_path, exist_ok=True)\n",
        "print(\"Complete!\")\n",
        "\n",
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "'  Here, we have a function that automatically loads the whole ensemble model (5 neural networks) '\n",
        "\n",
        "print(\"Loading Useful Functions...\")\n",
        "def load_ensembles(Phase1_path_model, Phase2_path_model):\n",
        "\n",
        "    Phase1_path = './Phase1_Pretrained-models/' + Phase1_path_model + '/'# folder for Phase I \n",
        "    Phase2_path = './Phase2_Pretrained-models/' + Phase2_path_model + '/'# folder for Phase II\n",
        "\n",
        "    Phase1_ensemble = tk.load_zoo(Phase1_path) # loading the Phase I ensemble (expect: 7)\n",
        "    Phase2_ensemble = tk.load_zoo(Phase2_path) # loading the Phase I ensemble (expect: 5)\n",
        "    return Phase1_ensemble, Phase2_ensemble\n",
        "\n",
        "' function for creating dataframes while computing cell counts during inference '\n",
        "\n",
        "def create_final_df(counts, times):\n",
        "    counts_df = pd.DataFrame(counts)\n",
        "    counts_df.columns = ['filename', 'sRBC', 'WBC', 'Other']\n",
        "    times_df = pd.DataFrame(times)\n",
        "    times_df.columns = ['time_secs']\n",
        "    final_df = pd.concat([counts_df, times_df], axis = 1)\n",
        "    return final_df\n",
        "print(\"Complete!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXMxHpkbIj9c"
      },
      "source": [
        "## Make Predictions.\r\n",
        "In the following cell, all whole channel images located in the Images_To_Be_Analyzed directory will be sent through the neural-network. Cells will be extracted and guesses will be made as to the identity of each. \r\n",
        "\r\n",
        "After each channel is analyzed, all current results will be shown, and when all channels are analyzed, the total counts for all channels will be shown. Results can be copied and pasted into programs like excel if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6-DqtjkIi2O",
        "cellView": "form"
      },
      "source": [
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "%%time \n",
        "\n",
        "\n",
        "counts, times = [], [] \n",
        "count_container, time_container = [], []\n",
        "import gc\n",
        "from skimage import measure\n",
        "sRBC_Thresh = [0.4]\n",
        "WBC_Thresh = [0.4]\n",
        "Other_Thresh = [0.9]\n",
        "batches = 4\n",
        "final_sRBC = 0\n",
        "final_WBC = 0\n",
        "final_Other = 0\n",
        "\n",
        "Phase1_names, Phase2_names = 'ce-jaccard_encoder-decoder-net', 'Resnet50'\n",
        "\n",
        "print(\"Loading Ensembles...\")\n",
        "Phase1_ensemble, Phase2_ensemble = load_ensembles(Phase1_names, Phase2_names)\n",
        "print(\"Complete!\")\n",
        "counts, times = [], [] \n",
        "print('==================================================================')\n",
        "for index, filenames in enumerate(os.listdir(channel_path)):\n",
        "    for rep in ((\".png\", \"\"), (\".jpg\", \"\")):\n",
        "        clean_filename = filenames.replace(*rep)\n",
        "    if clean_filename == \".ipynb_checkpoints\":\n",
        "      continue\n",
        "    print('Analysis:', index, '| Channel:', clean_filename)\n",
        "    print('==================================================================')\n",
        "    start = time.time()\n",
        "    channel = CountAdheredBloodCells(channel_path, filenames) # calling the class object\n",
        "    for batch in range(batches):\n",
        "      print(\"Analyzing Batch \" + str(batch + 1) + \"/4\")\n",
        "      print('==================================================================')\n",
        "      # calling the function to output cell counts\n",
        "      #sRBC, WBC, Others = channel.call_pipeline(Phase1_ensemble, Phase2_ensemble, sRBC_Thresh, WBC_Thresh, Other_Thresh)\n",
        "      mask = channel.call_Phase_One(Phase1_ensemble, Phase2_ensemble, sRBC_Thresh, WBC_Thresh, Other_Thresh, batch, batches)\n",
        "      gc.collect()\n",
        "      #print(\"Binary Mask Creation\")\n",
        "      mask = (mask == 2)*1\n",
        "      #print(\"Blob Labels Creation\")\n",
        "      blobLabels = measure.label(mask)\n",
        "      #print(\"Delete Mask\")\n",
        "      del mask\n",
        "      #print(\"Collect Garbage\")\n",
        "      gc.collect()\n",
        "      #print(\"Create Label Properties\")\n",
        "      labelProperties = measure.regionprops(blobLabels)\n",
        "      #print(\"Delete Blobs\")\n",
        "      del blobLabels\n",
        "      #print(\"Collect Garbage\")\n",
        "      gc.collect()\n",
        "      #print(\"Create Centroids\")\n",
        "      cell_Centroids = [prop.centroid for prop in labelProperties if prop.area > 60]\n",
        "      #print(\"Delete Label Properties\")\n",
        "      del labelProperties\n",
        "      gc.collect()\n",
        "      sRBC, WBC, Others = channel.call_Phase_Two(Phase1_ensemble, Phase2_ensemble, sRBC_Thresh, WBC_Thresh, Other_Thresh, cell_Centroids,batch, batches)\n",
        "      final_sRBC = final_sRBC + sRBC\n",
        "      final_WBC = final_WBC + WBC\n",
        "      final_Other = final_Other + Others\n",
        "      #print(final_sRBC,final_WBC,final_Other)\n",
        "    end = time.time()\n",
        "    run_time = end-start\n",
        "            \n",
        "    times.append([run_time])\n",
        "    counts.append([filenames, final_sRBC, final_WBC, final_Other])\n",
        "    final_sRBC = 0\n",
        "    final_WBC = 0\n",
        "    final_Other = 0\n",
        "    final_df = create_final_df(counts,times)\n",
        "    print(\"Here are the counts after the last channel:\")\n",
        "    print('==================================================================')\n",
        "    display(final_df)\n",
        "\n",
        "print(\"Here are the final counts of all the analyzed channels:\")\n",
        "print('==================================================================')\n",
        "display(final_df)\n",
        "\n",
        "   # final_df.to_csv(f'./AI-vs-Human_counts/{Phase1_name}_{Phase2_name}.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY-JaAXJEHbW"
      },
      "source": [
        "## Re-Initialize Image Directory For More Analysis\r\n",
        "IMPORTANT: It is recommended to do your analysis in batches, instead of uploading all whole channel images at once. After completing one batch, simply re-run this cell, which will clear out the Images_To_Be_Analyzed directory, and then you can upload more channels for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi4s1EZ4urHc",
        "cellView": "form"
      },
      "source": [
        "#@title <-- Click To Run Cell. Double Click Here To View Code.\n",
        "import shutil\n",
        "channel_path= './data/Images_To_Be_Analyzed/'\n",
        "if os.path.isdir(channel_path):\n",
        "  shutil.rmtree(channel_path)\n",
        "os.makedirs(channel_path, exist_ok=True)\n",
        "print(\"Complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}